{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed_value= 1111\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,LSTM, Dense, Flatten, Conv1D, Lambda, Reshape, RepeatVector\n",
    "from keras.layers.merge import concatenate, multiply,add\n",
    "from keras import regularizers\n",
    "# from keras.initializers import gloroadasdat_uniform\n",
    "from tqdm import tqdm\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import random as python_random\n",
    "from statsmodels.tsa.stattools import pacf,acf\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MSE(pred,gt):\n",
    "#     l = pred.shape[1]\n",
    "#     err = np.zeros((l))\n",
    "#     err2 = np.zeros((l))\n",
    "# #     gt = gt[-1440:,:]\n",
    "#     for i in range(l):\n",
    "#         err[i] = mse(pred[:,i],gt[:,i])\n",
    "#         err2[i] = mae(pred[:,i],gt[:,i])\n",
    "#     return err,err2\n",
    "\n",
    "def MSE(pred,gt):\n",
    "    l = pred.shape[0]\n",
    "    err = np.zeros((l))\n",
    "    err2 = np.zeros((l))\n",
    "#     gt = gt[-1440:,:]\n",
    "#     for i in range(l):\n",
    "    err[i] = mse(pred,gt)\n",
    "    err2[i] = mae(pred,gt)\n",
    "    return err,err2\n",
    "\n",
    "def metrics(pred,gt):\n",
    "    l = pred.shape[1]\n",
    "#     print(l)\n",
    "    err_mse = np.zeros((l))\n",
    "    err_mae = np.zeros((l))\n",
    "\n",
    "    for i in range(l):\n",
    "        err_mse[i] = mse(pred[:,i],gt[:,i])\n",
    "        err_mae[i] = mae(pred[:,i],gt[:,i])\n",
    "        \n",
    "    return err_mse,err_mae        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------data loading--------------\n",
    "\n",
    "d = \"./dataset/\" #---should be updated to match the path\n",
    "\n",
    "horizon = 1\n",
    "window_size=50\n",
    "\n",
    "data = np.asarray(pd.read_csv(d+\"traffic_30_with_std.csv\",usecols=['avg_flow']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----train/test split---------------\n",
    "train_d=data[:(int(.8*data.size)+1)]\n",
    "n_test = int(.1*data.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_input(data,window_size,horizon=1):\n",
    "    length=data.shape[0]\n",
    "    data=np.append(data,0)\n",
    "    y = np.zeros([length-window_size+1,horizon])\n",
    "    output=np.zeros([length-window_size+1,window_size])\n",
    "    for i in range(length-window_size+1):\n",
    "        output[i:i+1,:]=data[i:i+window_size]\n",
    "        y[i,:]= data[i+window_size:i+window_size+horizon]\n",
    "#         print(i)\n",
    "    return output.reshape(output.shape[0],window_size), y\n",
    "\n",
    "def make_k_input(data,horizon):\n",
    "    length = data.shape[0]\n",
    "    output= np.zeros([length+1-horizon,horizon])\n",
    "    for i in range(length-window_size-horizon+1):\n",
    "        output[i:i+1,:]=data[i:i+horizon]\n",
    "    return output.reshape(output.shape[0],horizon)\n",
    "\n",
    "def nonov_make_input(data,window_size,horizon=1):\n",
    "    length=data.shape[0]-window_size\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "\n",
    "    data = np.append(data,np.zeros([horizon-extra]))\n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "        \n",
    "    output=np.zeros([i_val,window_size])\n",
    "    y=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[i*horizon:(i*horizon)+window_size]\n",
    "        y[i,:]= data[(i*horizon)+window_size:(i*horizon)+window_size+horizon]\n",
    "        \n",
    "    return output.reshape(output.shape[0],window_size), y\n",
    "\n",
    "def nonov_make_k_input(data,horizon):\n",
    "    length = data.shape[0]\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "    data_app = np.repeat(data[-1],extra)\n",
    "    data = np.append(data,data_app)    \n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "    output=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[(i*horizon):(i*horizon)+horizon]\n",
    "    return output.reshape(output.shape[0],horizon)\n",
    "\n",
    "def logic_rules(data,preds):\n",
    "    day_sample=48\n",
    "    window=8\n",
    "    data=data[2:]\n",
    "    loop=preds.size//window\n",
    "    rem=preds.size%window\n",
    "    out_data=np.zeros((loop,window))\n",
    "    out_pred=np.zeros((loop,window))\n",
    "    for i in range(loop):\n",
    "        out_data[i,:]=data[i*window:i*window+window]\n",
    "        out_pred[i,:]=preds[i*window:i*window+window]\n",
    "    rem_data=data[-(48+rem):-48]\n",
    "    rem_pred=preds[-rem:]\n",
    "    return out_data,out_pred,rem_data,rem_pred\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=1\n",
    "window_size=50\n",
    "final_output=np.zeros((train_d.size-window_size))\n",
    "\n",
    "\n",
    "p_acf = pacf(train_d,100)[1:]\n",
    "indexes = np.squeeze(np.argwhere(np.abs(p_acf)>0.2))\n",
    "\n",
    "weightage=np.ndarray.flatten(np.abs(p_acf[indexes]))\n",
    "# weightage = weightage/np.sum(np.abs(weightage))\n",
    "size_of_weightage= weightage.size\n",
    "input_, label = make_input(data,window_size,horizon)\n",
    "output =np.zeros([input_.shape[0],horizon])\n",
    "weight_matrix=np.zeros([1,window_size])\n",
    "weight_matrix[0,indexes]=weightage\n",
    "# output = np.append(input_[:,-size_of_weightage:],output,axis=1)   \n",
    "for z in range(input_.shape[0]):\n",
    "#         temp=np.zeros{horizon}\n",
    "#     for j in range(horizon):\n",
    "#             print(output[z,j:j+size_of_weightage]*weightage)\n",
    "#         output[z,j+size_of_weightage]= np.sum((output[z,j:j+size_of_weightage]*np.flip(weightage))/np.sum(weightage))\n",
    "    output[z,0]= (np.sum(input_[z,:]*np.flip(weight_matrix)))/np.sum(weightage)\n",
    "\n",
    "# output=output[:,size_of_weightage:]\n",
    "temp=np.squeeze(np.ndarray.flatten(output))\n",
    "final_output=temp\n",
    "\n",
    "\n",
    "#-------------logic_rules---------------------\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean= np.mean(out_pred,axis=1).reshape(out_pred.shape[0],1)\n",
    "data_mean=np.mean(out_data,axis=1).reshape(out_data.shape[0],1)\n",
    "pred_std=np.std(out_pred,axis=1)\n",
    "data_std=np.std(out_data,axis=1)\n",
    "diff=np.abs(pred_mean-data_mean)\n",
    "a=np.zeros(0)\n",
    "f_pred=out_pred\n",
    "for i in range(out_pred.shape[0]):\n",
    "    if diff[i]<0.1*data_std[i]:\n",
    "        a=np.append(a,i)\n",
    "        f_pred[i] = out_pred[i,:]-pred_mean[i,:]+data_mean[i,:]\n",
    "# f_rem=pred_rem-np.mean(pred_rem)+np.mean(data_rem)\n",
    "f_rem=pred_rem\n",
    "temp1=np.ndarray.flatten(f_pred)\n",
    "temp1=np.append(temp1,f_rem)\n",
    "\n",
    "a=a[1:]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/home/chatta/logic_rules/results/pacf_preds/traffic_30_std/h1/preds_final.csv',temp[1:], fmt='%1.5f',delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
